{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76a71e0-2934-4a53-880b-1c6723ff6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkkamalesh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e57c1f10-3cc1-4e13-b287-c9316833380f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76bb87-7e66-4aaf-84db-4d0e2985df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda uninstall pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff99e3-d7eb-4faa-a0e3-68dbdaa8b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers[sentencepiece]\n",
    "!pip install datasets\n",
    "!pip install nltk\n",
    "!pip install rouge_score\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69701c7c-9b0a-4b0f-82d3-7d965625233f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/juno/wandb/run-20220628_204156-16o1so0n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kkamalesh/T5-small%20testing/runs/16o1so0n\" target=\"_blank\">sweet-forest-7</a></strong> to <a href=\"https://wandb.ai/kkamalesh/T5-small%20testing\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/kkamalesh/T5-small%20testing/runs/16o1so0n?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f423313b510>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"T5-small testing\", entity=\"kkamalesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c586898f-395d-43be-9ab5-0cc1a0fb80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer,T5ForConditionalGeneration,DataCollatorForSeq2Seq\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.nn.functional import relu\n",
    "from evaluate import load\n",
    "from datasets import load_metric\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "#torch.multiprocessing.set_start_method('spawn')\n",
    "import os\n",
    "\n",
    "BATCH_SIZE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1426d1d3-7ddf-4403-9646-ffb02780d42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37d5d08-6fcc-45b0-b36e-c3443ef4c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 28 20:28:05 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   38C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10135926-7104-46c4-a796-117fb015ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_plain=pd.read_csv('sample_text_2000samples_without_attributes.csv')\n",
    "df_combined=pd.read_csv('sample_text_with_attributes_auglow.csv')[['Augmented text','Target Text']]\n",
    "#df_attributes.rename(columns={'Augmented text':'Augmented Text'},inplace=True)\n",
    "#df_combined=pd.concat([df_plain[['Augmented Text','Target Text']],df_attributes[['Augmented Text','Target Text']]])\n",
    "df_combined=df_combined.sample(frac=1)\n",
    "df=df_combined.applymap(lambda x:x.replace('\\n',' [LINE] '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8831bb17-6620-4c3a-b45d-52e312f3df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df.iloc[:1600,:]\n",
    "df_test=df.iloc[1600:,:]\n",
    "len_train=df_train.shape[0]\n",
    "len_test=df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f683b73-d6fe-4819-8583-920f3b9be725",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=T5Tokenizer.from_pretrained('t5-small',model_max_length=int(1e30))\n",
    "model=T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc61f54-cd47-48e4-bd22-f0f2e71a7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 28 20:28:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   36C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f3df6b-82e5-423c-aa12-4c261c17ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARRIS TEETER, SHREDDED WHEAT CEREAL [LINE] WHOLE GRAIN WHEAT, SUGAR, SORBITOL, GELATIN, REDUCED IRON, NIACIN (NIACINAMIDE), ZINC (ZINC OXIDE), VITAMIN B6 (PYRIDOXINE HYDROCHLORIDE), FOLATE (FOLIC ACID), VITAMIN B2 (RIBOFLAVIN), VITAMIN B1 (THIAMIN HYDROCHLORIDE), VITAMIN B12, BHT (TO PRESERVE FRESHNESS). [LINE] Serving  1.0 cup [LINE] Quantity: 150g (Poids net égoutté : 90g) [LINE] Protein 9.09 g [LINE] Total lipid (fat) 1.82 g [LINE] Carbohydrate, by difference 81.82 g [LINE] Energy 345.0 kcal [LINE] Sugars, total 20.0 g [LINE] Carbohydrate, other 51.0 g [LINE] Fiber, total dietary 10.9 g [LINE] Fiber, soluble 2.0 g [LINE] Fiber, insoluble 9.0 g [LINE] Calcium, Ca 0.0 mg [LINE] Iron, Fe 29.45 mg [LINE] Magnesium, Mg 109.0 mg [LINE] Phosphorus, P 273.0 mg [LINE] Potassium, K 327.0 mg [LINE] Sodium, Na 18.0 mg [LINE] Zinc, Zn 6.82 mg [LINE] Copper, Cu 0.364 mg [LINE] Vitamin A, IU 0.0 IU [LINE] Vitamin C, total ascorbic acid 0.0 mg [LINE] Thiamin 1.0 mg [LINE] Riboflavin 0.773 mg [LINE] Niacin 9.091 mg [LINE] Vitamin B-6 0.909 mg [LINE] Vitamin B-12 2.73 mcg [LINE] Cholesterol 0.0 mg [LINE] Fatty acids, total trans 0.0 g [LINE] Fatty acids, total saturated 0.0 g [LINE] Fatty acids, total monounsaturated 0.0 g [LINE] Fatty acids, total polyunsaturated 0.91 g [LINE] Manufactured By Harris-Teeter Inc. [LINE] Product of United States\n"
     ]
    }
   ],
   "source": [
    "print(df['Target Text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56d17c64-b840-4737-8b65-8b23ed7e6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=tokenizer(df['Target Text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ec47ec-3196-49fe-9617-8e098a871017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARRIS TEETER, SHREDDED WHEAT CEREAL [LINE] WHOLE GRAIN WHEAT, SUGAR, SORBITOL, GELATIN, REDUCED IRON, NIACIN (NIACINAMIDE), ZINC (ZINC OXIDE), VITAMIN B6 (PYRIDOXINE HYDROCHLORIDE), FOLATE (FOLIC ACID), VITAMIN B2 (RIBOFLAVIN), VITAMIN B1 (THIAMIN HYDROCHLORIDE), VITAMIN B12, BHT (TO PRESERVE FRESHNESS). [LINE] Serving 1.0 cup [LINE] Quantity: 150g (Poids net égoutté : 90g) [LINE] Protein 9.09 g [LINE] Total lipid (fat) 1.82 g [LINE] Carbohydrate, by difference 81.82 g [LINE] Energy 345.0 kcal [LINE] Sugars, total 20.0 g [LINE] Carbohydrate, other 51.0 g [LINE] Fiber, total dietary 10.9 g [LINE] Fiber, soluble 2.0 g [LINE] Fiber, insoluble 9.0 g [LINE] Calcium, Ca 0.0 mg [LINE] Iron, Fe 29.45 mg [LINE] Magnesium, Mg 109.0 mg [LINE] Phosphorus, P 273.0 mg [LINE] Potassium, K 327.0 mg [LINE] Sodium, Na 18.0 mg [LINE] Zinc, Zn 6.82 mg [LINE] Copper, Cu 0.364 mg [LINE] Vitamin A, IU 0.0 IU [LINE] Vitamin C, total ascorbic acid 0.0 mg [LINE] Thiamin 1.0 mg [LINE] Riboflavin 0.773 mg [LINE] Niacin 9.091 mg [LINE] Vitamin B-6 0.909 mg [LINE] Vitamin B-12 2.73 mcg [LINE] Cholesterol 0.0 mg [LINE] Fatty acids, total trans 0.0 g [LINE] Fatty acids, total saturated 0.0 g [LINE] Fatty acids, total monounsaturated 0.0 g [LINE] Fatty acids, total polyunsaturated 0.91 g [LINE] Manufactured By Harris-Teeter Inc. [LINE] Product of United States</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(f['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e024ce4c-b1ba-4c24-9e6c-357d43f405a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk=tokenizer('My name is KAMALESH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6ffd14b-e174-4dd2-af88-10ca9d7c6ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is KAMALESH</s>'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tk.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45754380-1b92-42b9-ba47-d54d7d452791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        source=df.iloc[:,0].values\n",
    "        target=df.iloc[:,1].values\n",
    "        self.source_token=tokenizer(list(source))\n",
    "        self.target_token=tokenizer(list(target))\n",
    "        self.len=len(source)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #self.source_token.input_ids[idx]=torch.tensor(self.source_token.input_ids[idx],device=device,dtype=torch.float32)\n",
    "        #self.source_token.attention_mask[idx]=torch.tensor(self.source_token.attention_mask[idx],device=device,dtype=torch.float32)\n",
    "        #self.target_token.input_ids[idx]=torch.tensor(self.target_token.input_ids[idx],device=device,dtype=torch.float32)\n",
    "\n",
    "        return {'input_ids':self.source_token.input_ids[idx],\n",
    "               'attention_mask':self.source_token.attention_mask[idx],'labels': self.target_token.input_ids[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5ae8a-9f7f-4195-8cdf-3a1aced260ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc39265c-24e9-484f-b9a8-d9424e54ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer,return_tensors='pt')\n",
    "train_set=CreateDataset(df_train)\n",
    "test_set=CreateDataset(df_test)\n",
    "train_loader=DataLoader(train_set,batch_size=BATCH_SIZE,shuffle=True,collate_fn=data_collator,pin_memory=True)\n",
    "test_loader=DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=True,collate_fn=data_collator,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a2fb61-1a0a-40ba-af5a-bea6bafdf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e24b600d-bc1e-4709-9b81-b7a4e197a839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 4800, 16375, 24786,  ...,     0,     0,     0],\n",
       "         [   71, 16976, 24203,  ...,     0,     0,     0],\n",
       "         [    3,   122,   332,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    3, 10966, 11012,  ...,     0,     0,     0],\n",
       "         [  377, 20291,   354,  ...,     0,     0,     0],\n",
       "         [    3,  8579,  5249,  ..., 19120,   584,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([[ 4800, 16375, 24786,  ...,  -100,  -100,  -100],\n",
       "         [   71, 16976, 24203,  ...,  -100,  -100,  -100],\n",
       "         [    3, 25430, 13431,  ...,  -100,  -100,  -100],\n",
       "         ...,\n",
       "         [    3, 10966,   332,  ...,  -100,  -100,  -100],\n",
       "         [  377, 20291,  6299,  ...,  -100,  -100,  -100],\n",
       "         [ 2847, 13458,  5091,  ...,  -100,  -100,  -100]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e771f3e-2fb5-4de4-96bd-6887a748e402",
   "metadata": {},
   "source": [
    "model.to(device)\n",
    "batch_train=[]\n",
    "batch_test=[]\n",
    "for batch in test_loader:\n",
    "    batch_test.append({key:value.to(device) for key,value in batch.items()})\n",
    "for batch in train_loader:\n",
    "    batch_train.append({key:value.to(device) for key,value in batch.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8801f259-82ae-4027-9a19-66c4b1f76eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae98c8c-eed2-46ac-84a3-4563d58d018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c941a0f-5267-4815-9479-2246431d796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch={key:value.to(device) for key,value in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c5aa9c6-3895-467f-8189-a785474e34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu=load('bleu')\n",
    "rouge=load('rouge')\n",
    "train_lis=[]\n",
    "test_lis=[]\n",
    "def compute_metric(predicted,target,epoch,flag):\n",
    "    predicted=[tokenizer.decode(x,skip_special_tokens=True) for x in predicted]\n",
    "    target_bleu=[[tokenizer.decode(relu(x),skip_special_tokens=True)] for x in target]\n",
    "    target_rouge=[tokenizer.decode(relu(x),skip_special_tokens=True) for x in target]\n",
    "    bleu_score=bleu.compute(predictions=predicted,references=target_bleu)['bleu']\n",
    "    rouge_score=rouge.compute(predictions=predicted,references=target_rouge,use_aggregator=False)['rouge1']\n",
    "    precision=sum([x[0] for x in rouge_score])/BATCH_SIZE\n",
    "    recall=sum([x[1] for x in rouge_score])/BATCH_SIZE\n",
    "    fscore=sum([x[2] for x in rouge_score])/BATCH_SIZE\n",
    "    #print(predicted[0].device,bleu_score.device)\n",
    "    if flag==0:\n",
    "        if epoch==num_epochs-1:\n",
    "            train_lis.extend(predicted)\n",
    "        return Counter({'bleu_train':bleu_score,'precision_train':precision,'recall_train':recall,'f-score_train':fscore})\n",
    "    else:\n",
    "        if epoch==num_epochs-1:\n",
    "            test_lis.extend(predicted)\n",
    "        return Counter({'bleu_test':bleu_score,'precision_test':precision,'recall_test':recall,'f-score_test':fscore})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5f37f89-9dc5-40c4-920d-e76ddad28a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 28 09:13:55 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   40C    P0    34W /  70W |  11618MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f354b8-05d4-4627-ad2c-34e4c05e3c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/kkamalesh/T5-small%20testing/runs/16o1so0n?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7f40c00e4450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [21:36<3:14:30, 1296.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score_train:  0.05024949360648866  f-score_test:  0.055081901292791856  bleu_test:  2.3917069034283688e-06  bleu_train:  3.4353317368101124e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [43:12<2:52:48, 1296.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score_train:  0.0538752437037848  f-score_test:  0.05948982552827332  bleu_test:  1.117953770557857e-05  bleu_train:  3.902505394294708e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [1:04:51<2:31:23, 1297.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score_train:  0.057844979743025916  f-score_test:  0.05981590722074378  bleu_test:  2.3309231544710205e-06  bleu_train:  5.369965651189893e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [1:26:28<2:09:44, 1297.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score_train:  0.06030936757845928  f-score_test:  0.060869805892579176  bleu_test:  6.469917736513644e-06  bleu_train:  7.72114558078136e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [1:48:08<1:48:11, 1298.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score_train:  0.061441859632729995  f-score_test:  0.061720503071987655  bleu_test:  5.84691694013621e-06  bleu_train:  5.4312299213272726e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [2:09:53<1:26:41, 1300.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score_train:  0.06329507304502413  f-score_test:  0.06293356083070027  bleu_test:  7.948383293569004e-06  bleu_train:  8.226548647767807e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [2:31:32<1:05:00, 1300.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score_train:  0.0644247845859147  f-score_test:  0.06196341538707536  bleu_test:  6.302855485599692e-06  bleu_train:  9.116386529411074e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [2:53:16<43:22, 1301.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score_train:  0.0658932557312346  f-score_test:  0.06323602657063412  bleu_test:  4.482877789440081e-06  bleu_train:  1.2662239280085717e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [3:14:57<21:41, 1301.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-score_train:  0.06702018133160935  f-score_test:  0.06365804769472094  bleu_test:  4.860335538994294e-06  bleu_train:  1.696791813792668e-05\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "optimiser=optim.Adam(model.parameters())\n",
    "num_epochs=10\n",
    "#f=0\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    metrics_train=Counter({'bleu_train':0,'precision_train':0,'recall_train':0,'f-score_train':0})\n",
    "    metrics_test=Counter({'bleu_test':0,'precision_test':0,'recall_test':0,'f-score_test':0})\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        #print(f)\n",
    "        batch={key:value.to(device) for key,value in batch.items()}\n",
    "        #print('crossed-1')\n",
    "        outputs=model(**batch)\n",
    "        #print('crossed-2')\n",
    "        loss=outputs.loss\n",
    "        predicted_tokens=model.generate(batch['input_ids'])\n",
    "        #print('crossed-3')\n",
    "        metrics=compute_metric(predicted_tokens,batch['labels'],epoch=epoch,flag=0)\n",
    "        #print('crossed-4')\n",
    "        metrics_train+=metrics\n",
    "        loss.backward()\n",
    "        #print('crossed-5')\n",
    "        optimiser.step()\n",
    "        #print('crossed-6')\n",
    "        optimiser.zero_grad()\n",
    "        #print('crossed-7')\n",
    "        #f+=1\n",
    "        #print('crossed-8')\n",
    "        torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch={key:value.to(device) for key,value in batch.items()}\n",
    "            predicted_tokens=model.generate(batch['input_ids'])\n",
    "            metrics=compute_metric(predicted_tokens,batch['labels'],epoch=epoch,flag=1)\n",
    "            metrics_test+=metrics\n",
    "            torch.cuda.empty_cache()\n",
    "    metrics_train={key:values*(BATCH_SIZE/len_train) for key,values in dict(metrics_train).items()}\n",
    "    metrics_test={key:values*(BATCH_SIZE/len_test) for key,values in dict(metrics_test).items()}\n",
    "    print('f-score_train: ',metrics_train['f-score_train'],' f-score_test: ',metrics_test['f-score_test'],' bleu_test: ',metrics_test['bleu_test'],' bleu_train: ',metrics_train['bleu_train'])\n",
    "    wandb.log ({**metrics_train,**metrics_test})         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e5afc10-bbb8-4f14-9aef-dfe1c5b5e6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   13663 MB |   13663 MB |   17420 MB |    3757 MB |\n",
      "|       from large pool |   13662 MB |   13662 MB |   17412 MB |    3750 MB |\n",
      "|       from small pool |       1 MB |       2 MB |       8 MB |       7 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   13663 MB |   13663 MB |   17420 MB |    3757 MB |\n",
      "|       from large pool |   13662 MB |   13662 MB |   17412 MB |    3750 MB |\n",
      "|       from small pool |       1 MB |       2 MB |       8 MB |       7 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   13750 MB |   13752 MB |   13752 MB |    2048 KB |\n",
      "|       from large pool |   13748 MB |   13748 MB |   13748 MB |       0 KB |\n",
      "|       from small pool |       2 MB |       4 MB |       4 MB |    2048 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   88835 KB |  107907 KB |  745862 KB |  657027 KB |\n",
      "|       from large pool |   87936 KB |  106368 KB |  736640 KB |  648704 KB |\n",
      "|       from small pool |     899 KB |    2363 KB |    9222 KB |    8323 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     507    |     507    |     696    |     189    |\n",
      "|       from large pool |     416    |     416    |     548    |     132    |\n",
      "|       from small pool |      91    |      93    |     148    |      57    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     507    |     507    |     696    |     189    |\n",
      "|       from large pool |     416    |     416    |     548    |     132    |\n",
      "|       from small pool |      91    |      93    |     148    |      57    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     249    |     250    |     250    |       1    |\n",
      "|       from large pool |     248    |     248    |     248    |       0    |\n",
      "|       from small pool |       1    |       2    |       2    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      45    |      46    |      88    |      43    |\n",
      "|       from large pool |      43    |      44    |      58    |      15    |\n",
      "|       from small pool |       2    |       3    |      30    |      28    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0647ee-7161-46e9-9bb9-942290c4739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint({**metrics_train,**metrics_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64eed80-ac4e-4e8d-a4b3-db58570145ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1323b16-dc37-4e92-ac60-4067c692023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test=[]\n",
    "for batch in test_loader:\n",
    "    temp_batch=[tokenizer.decode(relu(x),skip_special_tokens=True) for x in batch['labels']]\n",
    "    target_test.extend(temp_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5b5ab-fdd1-4d40-9c25-040bfa35da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.DataFrame(list(zip(test_lis,target_test)),columns=['Predicted','Target'])\n",
    "final_df.to_csv('T5-small-results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
